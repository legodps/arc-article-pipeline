# Contains strings used repeatedly, storing in this file for consistency
ADDENDUM_RESULTS = 'Addendum Results:'
ADJUNCT_TOPICS = 'adjunctTopics'
ANSWER_CHOICES = 'answerChoices'
ANSWER_KEY = 'answerKey'
ARC_CHECKPOINT_FILE = 'arc_checkpoint_file'
ARC_DATA_SUBDIRECTORY = 'arc_data_subdirectory'
ARC_MODEL_SUBDIRECTORY = 'arc_model_subdirectory'
ARC_RESULTS_FILE = 'arc_results_file'
ARC_SOLVER_DIRECTORY = 'arc_solver_directory'
ARTICLE_COUNT = 'article_count'
ARTICLE_DIRECTORY = 'article_directory'
AVERAGE_CORRECT = 'average_correct'
AVERAGE_INCORRECT = 'average_incorrect'
AVERAGE_PERCENT_CORRECT = 'average_percent_correct'
AVERAGE_PERCENT_INCORRECT = 'average_percent_incorrect'
AVERAGE_INFORMATIVENESS = 'average_informativeness'
AVERAGE_PERCENT_UNANSWERED = 'average_percent_unanswered'
AVERAGE_UNANSWERED = 'average_unanswered'
BEING_ASKED = 'beingAsked'
BENCHMARK_SET_DIRECTORY = 'benchmark_set_directory'
CHECKPOINT_DIRECTORY = 'checkpoint_directory'
CHOICES = 'choices'
CONDA_ENVIRONMENT_NAME = 'conda_environment_name'
CONFIG_FILE = 'config_file'
CONTENT = 'content'
CORRECT = 'correct'
CORRECT_ANSWER = 'correctAnswer'
CORRECT_STANDARD_DEVIATION = 'correct_std_dev'
DECIMAL_DIGITS = 4
DIAGRAM_ANNOTATIONS = 'diagramAnnotations'
DISAGREEMENT = 'disagreement'
FILE = 'file'
FINAL_RESULTS_FILE = 'final_results_file'
GLOBAL_ID = 'globalID'
HOST = 'host'
ID = 'id'
INCORRECT = 'incorrect'
INCORRECT_STANDARD_DEVIATION = 'incorrect_std_dev'
INDEX = 'index'
INDEX_COUNT = 'index_count'
INDIVIDUAL_RESULTS = 'individual_results'
INDIVIDUAL_QUESTION_METRICS_FILE = 'individual_question_metrics_file'
INFORMATIVENESS_STANDARD_ERROR = 'informativeness_standard_error'
INSTRUCTIONAL_DIAGRAMS = 'instructionalDiagrams'
LABEL = 'label'
LESSON_NAME = 'lessonName'
MAPPING = 'mapping'
MAX_QUESTION_DISAGREEMENT = 'max_question_disagreement'
METRICS = 'Metrics'
NON_DIAGRAM_QUESTIONS = 'nonDiagramQuestions'
PARA_BODY = 'para_body'
PARAGRAPHS = 'paragraphs'
PERCENT_CORRECT = 'percent_correct'
PERCENT_INCORRECT = 'percent_incorrect'
PERCENT_UNANSWERED = 'percent_unanswered'
PORT = 'port'
PROCESSED_TEXT = 'processedText'
QUESTION = 'question'
QUESTION_COUNT = 'question_count'
QUESTION_DIRECTORY = 'question_directory'
QUESTION_ID = 'question_id'
QUESTION_SET = 'question_set'
QUESTION_SET_METRICS_FILE = 'question_set_metrics_file'
QUESTIONS = 'questions'
RANDOM_ANSWERING = 'random_answering'
RESULTS = 'results'
SQUID = 'squid'
STEM = 'stem'
TEXT = 'text'
TITLE = 'title'
TOPICS = 'topics'
TOTAL = 'total'
TOTAL_CORRECT = 'total_correct'
TOTAL_INCORRECT = 'total_incorrect'
TOTAL_INFORMATIVENESS = 'total_informativeness'
TOTAL_UNANSWERED = 'total_unanswered'
TQA = 'tqa'
UNANSWERED = 'unanswered'
UNANSWERD_STANDARD_DEVIATION = 'unanswered_std_dev'
ARC_CORPUS_INDEX = 'arc_corpus_index'

# Elasticsearch mapping values
ELASTICSEARCH_DOC = '_doc'
ELASTICSEARCH_ID = '_id'
ELASTICSEARCH_INDEX = '_index'
ELASTICSEARCH_TYPE = '_type'
ELASTICSEARCH_OP_TYPE = '_op_type'
ELASTICSEARCH_SOURCE = '_source'

# Files and Directories
ARC_DATA_FULL_WIPE_KEEP_FILES = [
    'ARC-Challenge-Dev.jsonl',
    'ARC-Challenge-Dev.csv',
    'ARC-Challenge-Train.jsonl',
    'ARC-Challenge-Train.csv',
    'ARC-Challenge-Test.csv'
]
ARC_DATA_SMALL_WIPE_KEEP_FILES = [
    'ARC-Challenge-Dev.jsonl',
    'ARC-Challenge-Dev.csv',
    'ARC-Challenge-Train.jsonl',
    'ARC-Challenge-Train.csv',
    'ARC-Challenge-Test.jsonl',
    'ARC-Challenge-Test.csv'
]
ARC_BENCHMARK_DIRECTORY = '/arc-benchmark'
ARC_CHALLENGE_TEST = 'ARC-Challenge-Test.jsonl'
BENCHMARK_CONFIG_YAML = 'benchmarkConfig.yaml'
ENV_DIRECTORY = '/env'
EVALUATE_SOLVER_FILEPATH = 'scripts/evaluate_solver.sh'
HTMLCOV_DIRECTORY = '/htmlcov'
JSON_EXTENSION = '.json'
JSONL_EXTENSION = '.jsonl'
TESTS_DIRECTORY = '/tests'
