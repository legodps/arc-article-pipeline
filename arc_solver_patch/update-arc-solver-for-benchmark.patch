Index: arc_solvers/processing/add_retrieved_text.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- arc_solvers/processing/add_retrieved_text.py	(revision 8f21cb821b3a457f25535ccd1b5cddb01ed1bc4e)
+++ arc_solvers/processing/add_retrieved_text.py	(date 1582581371966)
@@ -63,23 +63,23 @@
 from arc_solvers.processing.es_search import EsSearch, EsHit
 
 MAX_HITS = 8
-es_search = EsSearch(max_hits_per_choice=MAX_HITS, max_hits_retrieved=100)
 
 
-def add_retrieved_text(qa_file, output_file):
+def add_retrieved_text(qa_file, output_file, index):
+    es_search = EsSearch(max_hits_per_choice=MAX_HITS, max_hits_retrieved=100, indices=index)
     with open(output_file, 'w') as output_handle, open(qa_file, 'r') as qa_handle:
         print("Writing to {} from {}".format(output_file, qa_file))
         line_tqdm = tqdm(qa_handle, dynamic_ncols=True)
         for line in line_tqdm:
             json_line = json.loads(line)
             num_hits = 0
-            for output_dict in add_hits_to_qajson(json_line):
+            for output_dict in add_hits_to_qajson(json_line, es_search):
                 output_handle.write(json.dumps(output_dict) + "\n")
                 num_hits += 1
             line_tqdm.set_postfix(hits=num_hits)
 
 
-def add_hits_to_qajson(qa_json: JsonDict):
+def add_hits_to_qajson(qa_json: JsonDict, es_search):
     question_text = qa_json["question"]["stem"]
     choices = [choice["text"] for choice in qa_json["question"]["choices"]]
     hits_per_choice = es_search.get_hits_for_question(question_text, choices)
@@ -133,4 +133,4 @@
     if len(sys.argv) < 3:
         raise ValueError("Provide at least two arguments: "
                          "question-answer json file, output file name")
-    add_retrieved_text(sys.argv[1], sys.argv[2])
+    add_retrieved_text(sys.argv[1], sys.argv[2], sys.argv[3])
Index: scripts/evaluate_solver.sh
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- scripts/evaluate_solver.sh	(revision 8f21cb821b3a457f25535ccd1b5cddb01ed1bc4e)
+++ scripts/evaluate_solver.sh	(date 1582239076863)
@@ -7,6 +7,7 @@
 
 input_file=$1
 model_dir=$2
+index=$3
 # Set this to name your run
 run_name=default
 if [ -z $model_dir ] ; then
@@ -30,9 +31,10 @@
 
 # Collect hits from ElasticSearch for each question + answer choice
 if [ ! -f ${input_file_with_hits} ]; then
-  python arc_solvers/processing/add_retrieved_text.py \
+  python3.6 arc_solvers/processing/add_retrieved_text.py \
     ${input_file} \
-    ${input_file_with_hits}.$$
+    ${input_file_with_hits}.$$ \
+    ${index}
   mv ${input_file_with_hits}.$$ ${input_file_with_hits}
 fi
 
@@ -40,7 +42,7 @@
 # the JSONL file where premise is the retrieved HIT for each answer choice and hypothesis is the
 # question + answer choice converted into a statement.
 if [ ! -f ${input_file_as_entailment} ]; then
-  python arc_solvers/processing/convert_to_entailment.py \
+  python3.6 arc_solvers/processing/convert_to_entailment.py \
     ${input_file_with_hits} \
     ${input_file_as_entailment}.$$
   mv ${input_file_as_entailment}.$$ ${input_file_as_entailment}
@@ -56,7 +58,7 @@
 
 # Compute entailment predictions for each premise and hypothesis
 if [ ! -f ${entailment_predictions} ]; then
-  python arc_solvers/run.py predict \
+  python3.6 arc_solvers/run.py predict \
     --output-file ${entailment_predictions}.$$ --silent \
     ${model_dir}/model.tar.gz ${input_file_as_entailment_with_struct}
   mv ${entailment_predictions}.$$ ${entailment_predictions}
@@ -65,11 +67,11 @@
 # Compute qa predictions by aggregating the entailment predictions for each question+answer
 # choice (using max)
 if [ ! -f ${qa_predictions} ]; then
-  python arc_solvers/processing/evaluate_predictions.py \
+  python3.6 arc_solvers/processing/evaluate_predictions.py \
     ${entailment_predictions} \
     ${input_file} \
     ${qa_predictions}.$$
   mv ${qa_predictions}.$$ ${qa_predictions}
 fi
 
-python arc_solvers/processing/calculate_scores.py ${qa_predictions}
+python3.6 arc_solvers/processing/calculate_scores.py ${qa_predictions}
Index: arc_solvers/processing/es_search.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- arc_solvers/processing/es_search.py	(revision 8f21cb821b3a457f25535ccd1b5cddb01ed1bc4e)
+++ arc_solvers/processing/es_search.py	(date 1584998263492)
@@ -23,7 +23,7 @@
 class EsSearch:
     def __init__(self,
                  es_client: str = "localhost",
-                 indices: str = "arc_corpus",
+                 indices: str = "arc-corpus",
                  max_question_length: int = 1000,
                  max_hits_retrieved: int = 500,
                  max_hit_length: int = 300,
@@ -71,8 +71,7 @@
                             }}
                         ],
                         "filter": [
-                            {"match": {"text": choice}},
-                            {"type": {"value": "sentence"}}
+                            {"match": {"text": choice}}
                         ]
                     }
                 }}
Index: arc_solvers/processing/evaluate_predictions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- arc_solvers/processing/evaluate_predictions.py	(revision 8f21cb821b3a457f25535ccd1b5cddb01ed1bc4e)
+++ arc_solvers/processing/evaluate_predictions.py	(date 1582239076855)
@@ -91,12 +91,13 @@
         num_questions = 0
         for line in qa_handle:
             json_line = json.loads(line)
-            id = json_line["id"]
+            id = str(json_line["id"])
             answer_choices = json_line["question"]["choices"]
             for choice in answer_choices:
                 choice_text = choice["text"]
                 # if we have any entailment prediction for this answer choice, pick the
-                if id in qid_choice_predictions and choice_text in qid_choice_predictions[id]:
+
+                if id in qid_choice_predictions and choice_text in qid_choice_predictions[str(id)]:
                     update_choice_with_scores(qid_choice_predictions[id][choice_text], choice)
                 else:
                     update_choice_with_scores([], choice)
Index: scripts/index-corpus.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- scripts/index-corpus.py	(revision 8f21cb821b3a457f25535ccd1b5cddb01ed1bc4e)
+++ scripts/index-corpus.py	(date 1588712058367)
@@ -25,7 +25,7 @@
     index_name = args.index
 
     # Document Type constant
-    TYPE = "sentence"
+    TYPE = "_doc"
 
     # Get an ElasticSearch client
     es = Elasticsearch(hosts=[{"host": args.host, "port": args.port}], retries=3, timeout=60)
Index: scripts/download_data.sh
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- scripts/download_data.sh	(revision 8f21cb821b3a457f25535ccd1b5cddb01ed1bc4e)
+++ scripts/download_data.sh	(date 1582384582700)
@@ -27,7 +27,7 @@
 cd ..
 
 # Build the index
-python scripts/index-corpus.py \
+python3.6 scripts/index-corpus.py \
 	data/ARC-V1-Feb2018/ARC_Corpus.txt \
 	arc_corpus \
 	$ES_HOST
Index: arc_solvers/processing/calculate_scores.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- arc_solvers/processing/calculate_scores.py	(revision 8f21cb821b3a457f25535ccd1b5cddb01ed1bc4e)
+++ arc_solvers/processing/calculate_scores.py	(date 1589495736723)
@@ -38,6 +38,7 @@
         partially_correct = 0
         correct = 0
         incorrect = 0
+        individual_results = {}
         for line in qa_handle:
             json_line = json.loads(line)
             answer_choices = json_line["question"]["choices"]
@@ -50,10 +51,13 @@
             if answer_key in selected_answers:
                 question_score = 1 / len(selected_answers)
                 if question_score < 1:
+                    individual_results[str(json_line['id'])] = 'unanswered'
                     partially_correct += 1
                 else:
+                    individual_results[str(json_line['id'])] = 'correct'
                     correct += 1
             else:
+                individual_results[str(json_line['id'])] = 'incorrect'
                 question_score = 0
                 incorrect += 1
             total_score += question_score
@@ -68,6 +72,9 @@
           Partial:      {}
                 """.format(total_score, num_questions, (total_score / num_questions)*100,
                            correct, incorrect, partially_correct))
+        print(f'Addendum Results:')
+        print(json.dumps(individual_results))
+
 
 
 if __name__ == "__main__":
